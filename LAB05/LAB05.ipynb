{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bài tập 1.\n",
    " - <ins>Yêu cầu</ins>: Ý tưởng cơ bản của thuật toán ``Support Vector Machine`` (``SVM``) là gì? Ý tưởng của thuật toán biên mềm (``soft margin``) ``SVM``. Nêu ý nghĩa của siêu tham số ``C`` trong bài toán cực tiểu hàm mất mát.\n",
    "\n",
    "  1. Ý tưởng cơ bản của SVM là đưa toàn bộ dataset vào không gian nhiều chiều (n chiều), từ đó tìm ra mặt phẳng thích hợp nhất (hyperplane) để phân chia\n",
    "  2. Support Vector Machine thuần (hard margin) thì gặp hai vấn đề chính đó là nó chỉ hoạt động trên dataset ``Linearly Separable`` và thứ 2 đó là nó khá nhạy cảm với biến nhiễu (sensitive to noise). Để tránh vấn đề này, chúng ta cần sử dụng một mô hình linh hoạt \n",
    "hơn. Nhiệm vụ của nó là tìm được mặt phẳng vẫn phân loại tốt nhưng chấp nhận sai lệch ở một mức độ chấp nhận được.\n",
    "  3. Tham số `C` là hằng số dương giúp cân đối độ lớn của margin và sự hy sinh của các điểm nằm trong vùng không an toàn. Khi $C = \\infty $ hoặc rất lớn, Soft Margin SVM trở thành Hard Margin SVM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bài tập 2.\n",
    " - <ins>Yêu cầu</ins>: Sử dụng mô hình ``SVM`` thuộc thư viện ``sklearn`` để xây dựng mô hình phân loại dựa trên tập dữ liệu huấn luyện ``X_train``, ``y_train``. Hãy nhận xét về tỉ lệ nhãn ``0`` và ``1`` trong bộ dữ liệu đã cho như đoạn code bên dưới. Hãy thử thay đổi giá trị của tham số ``C`` và nhận xét các độ đo ``Recall``, ``Precison``, ``F1-score``, và ``Accuracy`` của mô hình thu được trên tập dữ liệu kiểm tra ``X_test``, ``y_test``.\n",
    " - Nguồn tham khảo dữ liệu ``thyroid_sick.csv``: https://archive.ics.uci.edu/ml/datasets/Thyroid+Disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import itertools\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "df = pd.read_csv('thyroid_sick.csv')\n",
    "X = df[[column_name for column_name in df.columns if column_name != 'classes']]\n",
    "y = df[['classes']]\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X.astype(float))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "classes\n0    2864\n1     288\ndtype: int64"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "df.pivot_table(index =['classes'], aggfunc='size')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Nhận xét:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Result with C = 0.5\n              precision    recall  f1-score   support\n\n           0       0.91      0.99      0.95       274\n           1       0.88      0.33      0.48        42\n\n    accuracy                           0.91       316\n   macro avg       0.89      0.66      0.72       316\nweighted avg       0.90      0.91      0.89       316\n\nResult with C = 1.0\n              precision    recall  f1-score   support\n\n           0       0.94      0.99      0.97       274\n           1       0.93      0.62      0.74        42\n\n    accuracy                           0.94       316\n   macro avg       0.94      0.81      0.86       316\nweighted avg       0.94      0.94      0.94       316\n\nResult with C = 1.5\n              precision    recall  f1-score   support\n\n           0       0.94      0.99      0.97       274\n           1       0.93      0.62      0.74        42\n\n    accuracy                           0.94       316\n   macro avg       0.94      0.81      0.86       316\nweighted avg       0.94      0.94      0.94       316\n\nResult with C = 2.0\n              precision    recall  f1-score   support\n\n           0       0.95      0.99      0.97       274\n           1       0.90      0.64      0.75        42\n\n    accuracy                           0.94       316\n   macro avg       0.92      0.82      0.86       316\nweighted avg       0.94      0.94      0.94       316\n\nResult with C = 2.5\n              precision    recall  f1-score   support\n\n           0       0.95      0.99      0.97       274\n           1       0.90      0.64      0.75        42\n\n    accuracy                           0.94       316\n   macro avg       0.92      0.82      0.86       316\nweighted avg       0.94      0.94      0.94       316\n\nResult with C = 3.0\n              precision    recall  f1-score   support\n\n           0       0.95      0.99      0.97       274\n           1       0.91      0.69      0.78        42\n\n    accuracy                           0.95       316\n   macro avg       0.93      0.84      0.88       316\nweighted avg       0.95      0.95      0.95       316\n\nResult with C = 3.5\n              precision    recall  f1-score   support\n\n           0       0.96      0.99      0.97       274\n           1       0.91      0.74      0.82        42\n\n    accuracy                           0.96       316\n   macro avg       0.94      0.86      0.90       316\nweighted avg       0.95      0.96      0.95       316\n\nResult with C = 4.0\n              precision    recall  f1-score   support\n\n           0       0.97      0.99      0.98       274\n           1       0.92      0.79      0.85        42\n\n    accuracy                           0.96       316\n   macro avg       0.94      0.89      0.91       316\nweighted avg       0.96      0.96      0.96       316\n\nResult with C = 4.5\n              precision    recall  f1-score   support\n\n           0       0.97      0.99      0.98       274\n           1       0.92      0.79      0.85        42\n\n    accuracy                           0.96       316\n   macro avg       0.94      0.89      0.91       316\nweighted avg       0.96      0.96      0.96       316\n\nResult with C = 5.0\n              precision    recall  f1-score   support\n\n           0       0.97      0.99      0.98       274\n           1       0.92      0.79      0.85        42\n\n    accuracy                           0.96       316\n   macro avg       0.94      0.89      0.91       316\nweighted avg       0.96      0.96      0.96       316\n\nResult with C = 5.5\n              precision    recall  f1-score   support\n\n           0       0.97      0.99      0.98       274\n           1       0.92      0.79      0.85        42\n\n    accuracy                           0.96       316\n   macro avg       0.94      0.89      0.91       316\nweighted avg       0.96      0.96      0.96       316\n\nResult with C = 6.0\n              precision    recall  f1-score   support\n\n           0       0.97      0.99      0.98       274\n           1       0.92      0.81      0.86        42\n\n    accuracy                           0.97       316\n   macro avg       0.95      0.90      0.92       316\nweighted avg       0.96      0.97      0.96       316\n\nResult with C = 6.5\n              precision    recall  f1-score   support\n\n           0       0.97      0.99      0.98       274\n           1       0.92      0.79      0.85        42\n\n    accuracy                           0.96       316\n   macro avg       0.94      0.89      0.91       316\nweighted avg       0.96      0.96      0.96       316\n\nResult with C = 7.0\n              precision    recall  f1-score   support\n\n           0       0.97      0.99      0.98       274\n           1       0.92      0.79      0.85        42\n\n    accuracy                           0.96       316\n   macro avg       0.94      0.89      0.91       316\nweighted avg       0.96      0.96      0.96       316\n\nResult with C = 7.5\n              precision    recall  f1-score   support\n\n           0       0.97      0.99      0.98       274\n           1       0.92      0.79      0.85        42\n\n    accuracy                           0.96       316\n   macro avg       0.94      0.89      0.91       316\nweighted avg       0.96      0.96      0.96       316\n\nResult with C = 8.0\n              precision    recall  f1-score   support\n\n           0       0.97      0.99      0.98       274\n           1       0.92      0.79      0.85        42\n\n    accuracy                           0.96       316\n   macro avg       0.94      0.89      0.91       316\nweighted avg       0.96      0.96      0.96       316\n\nResult with C = 8.5\n              precision    recall  f1-score   support\n\n           0       0.97      0.99      0.98       274\n           1       0.92      0.79      0.85        42\n\n    accuracy                           0.96       316\n   macro avg       0.94      0.89      0.91       316\nweighted avg       0.96      0.96      0.96       316\n\nResult with C = 9.0\n              precision    recall  f1-score   support\n\n           0       0.97      0.99      0.98       274\n           1       0.92      0.79      0.85        42\n\n    accuracy                           0.96       316\n   macro avg       0.94      0.89      0.91       316\nweighted avg       0.96      0.96      0.96       316\n\nResult with C = 9.5\n              precision    recall  f1-score   support\n\n           0       0.97      0.99      0.98       274\n           1       0.92      0.79      0.85        42\n\n    accuracy                           0.96       316\n   macro avg       0.94      0.89      0.91       316\nweighted avg       0.96      0.96      0.96       316\n\nResult with C = 10.0\n              precision    recall  f1-score   support\n\n           0       0.97      0.99      0.98       274\n           1       0.92      0.79      0.85        42\n\n    accuracy                           0.96       316\n   macro avg       0.94      0.89      0.91       316\nweighted avg       0.96      0.96      0.96       316\n\nThe best accuracy was with 0.9651898734177216 with C= 10.0\n"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "C_parameter = 10.5\n",
    "mean_acc = []\n",
    "for n in np.arange(0.5, C_parameter, 0.5):\n",
    "    \n",
    "    #Train Model and Predict  \n",
    "    clf = svm.SVC(C=n).fit(X_train,y_train)\n",
    "    yhat=clf.predict(X_test)\n",
    "    cnf_matrix = confusion_matrix(y_test, yhat)\n",
    "\n",
    "    mean_acc.append(float(accuracy_score(y_test, yhat)))\n",
    "    print(\"Result with C = \" + str(n))\n",
    "    np.set_printoptions(precision=2)\n",
    "    print (classification_report(y_test, yhat))\n",
    "\n",
    "print( \"The best accuracy was with\", max(mean_acc), \"with C=\", n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bài tập 3.\n",
    " - <ins>Yêu cầu</ins>: Ý tưởng của hàm ``kernel`` $K(\\dots, \\dots)$ là gì? Khi nào chúng ta áp dụng hàm ``kernel``? Chúng ta có cần biết biểu thức của hàm $\\Phi(x)$ không?\n",
    " 1. Kernel SVM là việc đi tìm một hàm số biến đổi dữ liệu $x$ từ không gian feature ban đầu thành dữ liệu trong một không gian mới bằng hàm số $\\Phi(\\mathbf{x})$. Hàm số này cần thoả mãn mục đích đó là tronng không gian mới, dữ liệu giữa hai classes là phân biệt tuyến tính hoặc gần như phần biệt tuyến tính.\n",
    " 2. Chúng ta áp dụng hàm ``kernel`` khi dữ liệu không phân biệt tuyến tính, Với dữ liệu gần phân biệt tuyến tính, linear và poly kernels cho kết quả tốt hơn.\n",
    " 3. Ta cần phải biết biểu thức của hàng $\\Phi(x)$ vì với mỗi bộ dữ liệu sẽ có những hàm kernels khác nhau từ đó chúng ta sẽ phải chọn những hàm $\\Phi(x)$ tương ứng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bài tập 4.\n",
    " - <ins>Yêu cầu</ins>: Cho điểm dữ liệu trong không gian hai chiều $x = [x_1, x_2]^T$ và hàm biến đổi sang không gian năm chiều $\\Phi(x) = [1, \\sqrt{2}x_1, \\sqrt{2}x_2, x_1^2, \\sqrt{2}x_1x_2, x_2^2]^T$. Hãy tính hàm ``kernel`` $K(a, b)$.\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\Phi(\\mathbf{x})^T\\Phi(\\mathbf{z}) &=& [1, \\sqrt{2} x_1, \\sqrt{2} x_2, x_1^2, \\sqrt{2} x_1x_2, x_2^2] [1, \\sqrt{2} z_1, \\sqrt{2} z_2, z_1^2, \\sqrt{2} z_1z_2, z_2^2]^T \\\\\n",
    "&=& 1 + 2x_1z_1 + 2x_2z_2 + x_1^2x_2^2 + 2x_1z_1x_2z_2 + x_2^2z_2^2 \\\\\n",
    "&=& (1 + x_1z_1 + x_2z_2)^2 = (1 + \\mathbf{x}^T\\mathbf{z})^2 = k(\\mathbf{x}, \\mathbf{z})\n",
    "\\end{eqnarray}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bài tập 5.\n",
    " - <ins>Yêu cầu</ins>: Giả sử bạn dùng bộ phân loại ``SVM`` với hàm ``kernel`` (radial basis function) ``RBF`` cho tập huấn luyện và thấy mô hình phân loại chưa tốt. Để cải thiện, bạn sẽ giảm hay tăng tham số $\\gamma$ trong công thức hàm ``kernel``, tham số ``C`` trong hàm mất mát."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bài tập 6. (Exercise 9 trang 174, Chapter 5: Support Vector Machines)\n",
    " - <ins>Yêu cầu</ins>: Huấn luyện một bộ phân lớp ``SVM`` dựa trên bộ dữ liệu ``MNIST`` (dùng để phân loại hình ảnh các ký tự số có cùng kích thước). Bởi vì bộ phân loại ``SVM`` là bộ phân lớp nhị phân, chúng ta sẽ cần sử dụng chiến thuật ``one-versus-the-rest`` để phân loại tất cả ``10`` ký tự số (trong thực tế chúng ta chỉ dùng chiến thuật ``one-versus-one`` trong các trường hợp dữ liệu nhỏ). Bạn hãy báo cáo độ chính xác (``accuracy``) của mô hình đã huấn luyện trên tập test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784', version=1, cache=True)\n",
    "\n",
    "X = mnist[\"data\"]\n",
    "y = mnist[\"target\"].astype(np.uint8)\n",
    "\n",
    "X_train = X[:60000]\n",
    "y_train = y[:60000]\n",
    "X_test = X[60000:]\n",
    "y_test = y[60000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bài tập 7. (Exercise 10 trang 174, Chapter 5: Support Vector Machines)\n",
    " - <ins>Yêu cầu</ins>: Hãy huấn luyện một mô hình hồi quy tuyến tính với dữ liệu giá nhà ``California housing dataset``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Downloading Cal. housing from https://ndownloader.figshare.com/files/5976036 to C:\\Users\\Quang\\scikit_learn_data\n"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "X = housing[\"data\"]\n",
    "y = housing[\"target\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
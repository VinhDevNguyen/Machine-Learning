{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4-final"
    },
    "colab": {
      "name": "LAB05.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0798M6RGo-4g",
        "colab_type": "text"
      },
      "source": [
        "### Bài tập 1.\n",
        " - <ins>Yêu cầu</ins>: Ý tưởng cơ bản của thuật toán ``Support Vector Machine`` (``SVM``) là gì? Ý tưởng của thuật toán biên mềm (``soft margin``) ``SVM``. Nêu ý nghĩa của siêu tham số ``C`` trong bài toán cực tiểu hàm mất mát.\n",
        "\n",
        "  1. Ý tưởng cơ bản của SVM là đưa toàn bộ dataset vào không gian nhiều chiều (n chiều), từ đó tìm ra mặt phẳng thích hợp nhất (hyperplane) để phân chia\n",
        "  2. Support Vector Machine thuần (hard margin) thì gặp hai vấn đề chính đó là nó chỉ hoạt động trên dataset ``Linearly Separable`` và thứ 2 đó là nó khá nhạy cảm với biến nhiễu (sensitive to noise). Để tránh vấn đề này, chúng ta cần sử dụng một mô hình linh hoạt \n",
        "hơn. Nhiệm vụ của nó là tìm được mặt phẳng vẫn phân loại tốt nhưng chấp nhận sai lệch ở một mức độ chấp nhận được.\n",
        "  3. Tham số `C` là hằng số dương giúp cân đối độ lớn của margin và sự hy sinh của các điểm nằm trong vùng không an toàn. Khi $C = \\infty $ hoặc rất lớn, Soft Margin SVM trở thành Hard Margin SVM."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8tquRouo-4i",
        "colab_type": "text"
      },
      "source": [
        "### Bài tập 2.\n",
        " - <ins>Yêu cầu</ins>: Sử dụng mô hình ``SVM`` thuộc thư viện ``sklearn`` để xây dựng mô hình phân loại dựa trên tập dữ liệu huấn luyện ``X_train``, ``y_train``. Hãy nhận xét về tỉ lệ nhãn ``0`` và ``1`` trong bộ dữ liệu đã cho như đoạn code bên dưới. Hãy thử thay đổi giá trị của tham số ``C`` và nhận xét các độ đo ``Recall``, ``Precison``, ``F1-score``, và ``Accuracy`` của mô hình thu được trên tập dữ liệu kiểm tra ``X_test``, ``y_test``.\n",
        " - Nguồn tham khảo dữ liệu ``thyroid_sick.csv``: https://archive.ics.uci.edu/ml/datasets/Thyroid+Disease"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghlAQ49bo-4k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "import itertools\n",
        "import numpy as np\n",
        "from sklearn import preprocessing\n",
        "\n",
        "df = pd.read_csv('thyroid_sick.csv')\n",
        "X = df[[column_name for column_name in df.columns if column_name != 'classes']]\n",
        "y = df[['classes']]\n",
        "X = preprocessing.StandardScaler().fit(X).transform(X.astype(float))\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUo_bGbHo-4p",
        "colab_type": "code",
        "colab": {},
        "outputId": "ef9ba5c1-4b51-4f33-8654-7e9d58c66eb6"
      },
      "source": [
        "df.pivot_table(index =['classes'], aggfunc='size')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "classes\n",
              "0    2864\n",
              "1     288\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1eVdWuWo-4y",
        "colab_type": "text"
      },
      "source": [
        "* Nhận xét:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NjYzfV_To-4z",
        "colab_type": "code",
        "colab": {},
        "outputId": "1176ba14-2ca1-49d6-dd41-ea447a42ea0b"
      },
      "source": [
        "from sklearn import svm\n",
        "C_parameter = 10.5\n",
        "mean_acc = []\n",
        "for n in np.arange(0.5, C_parameter, 0.5):\n",
        "    \n",
        "    #Train Model and Predict  \n",
        "    clf = svm.SVC(C=n).fit(X_train,y_train)\n",
        "    yhat=clf.predict(X_test)\n",
        "    cnf_matrix = confusion_matrix(y_test, yhat)\n",
        "\n",
        "    mean_acc.append(float(accuracy_score(y_test, yhat)))\n",
        "    print(\"Result with C = \" + str(n))\n",
        "    np.set_printoptions(precision=2)\n",
        "    print (classification_report(y_test, yhat))\n",
        "\n",
        "print( \"The best accuracy was with\", max(mean_acc), \"with C=\", n)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Result with C = 0.5\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.99      0.95       274\n",
            "           1       0.88      0.33      0.48        42\n",
            "\n",
            "    accuracy                           0.91       316\n",
            "   macro avg       0.89      0.66      0.72       316\n",
            "weighted avg       0.90      0.91      0.89       316\n",
            "\n",
            "Result with C = 1.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.99      0.97       274\n",
            "           1       0.93      0.62      0.74        42\n",
            "\n",
            "    accuracy                           0.94       316\n",
            "   macro avg       0.94      0.81      0.86       316\n",
            "weighted avg       0.94      0.94      0.94       316\n",
            "\n",
            "Result with C = 1.5\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.99      0.97       274\n",
            "           1       0.93      0.62      0.74        42\n",
            "\n",
            "    accuracy                           0.94       316\n",
            "   macro avg       0.94      0.81      0.86       316\n",
            "weighted avg       0.94      0.94      0.94       316\n",
            "\n",
            "Result with C = 2.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.99      0.97       274\n",
            "           1       0.90      0.64      0.75        42\n",
            "\n",
            "    accuracy                           0.94       316\n",
            "   macro avg       0.92      0.82      0.86       316\n",
            "weighted avg       0.94      0.94      0.94       316\n",
            "\n",
            "Result with C = 2.5\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.99      0.97       274\n",
            "           1       0.90      0.64      0.75        42\n",
            "\n",
            "    accuracy                           0.94       316\n",
            "   macro avg       0.92      0.82      0.86       316\n",
            "weighted avg       0.94      0.94      0.94       316\n",
            "\n",
            "Result with C = 3.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.99      0.97       274\n",
            "           1       0.91      0.69      0.78        42\n",
            "\n",
            "    accuracy                           0.95       316\n",
            "   macro avg       0.93      0.84      0.88       316\n",
            "weighted avg       0.95      0.95      0.95       316\n",
            "\n",
            "Result with C = 3.5\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.99      0.97       274\n",
            "           1       0.91      0.74      0.82        42\n",
            "\n",
            "    accuracy                           0.96       316\n",
            "   macro avg       0.94      0.86      0.90       316\n",
            "weighted avg       0.95      0.96      0.95       316\n",
            "\n",
            "Result with C = 4.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98       274\n",
            "           1       0.92      0.79      0.85        42\n",
            "\n",
            "    accuracy                           0.96       316\n",
            "   macro avg       0.94      0.89      0.91       316\n",
            "weighted avg       0.96      0.96      0.96       316\n",
            "\n",
            "Result with C = 4.5\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98       274\n",
            "           1       0.92      0.79      0.85        42\n",
            "\n",
            "    accuracy                           0.96       316\n",
            "   macro avg       0.94      0.89      0.91       316\n",
            "weighted avg       0.96      0.96      0.96       316\n",
            "\n",
            "Result with C = 5.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98       274\n",
            "           1       0.92      0.79      0.85        42\n",
            "\n",
            "    accuracy                           0.96       316\n",
            "   macro avg       0.94      0.89      0.91       316\n",
            "weighted avg       0.96      0.96      0.96       316\n",
            "\n",
            "Result with C = 5.5\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98       274\n",
            "           1       0.92      0.79      0.85        42\n",
            "\n",
            "    accuracy                           0.96       316\n",
            "   macro avg       0.94      0.89      0.91       316\n",
            "weighted avg       0.96      0.96      0.96       316\n",
            "\n",
            "Result with C = 6.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98       274\n",
            "           1       0.92      0.81      0.86        42\n",
            "\n",
            "    accuracy                           0.97       316\n",
            "   macro avg       0.95      0.90      0.92       316\n",
            "weighted avg       0.96      0.97      0.96       316\n",
            "\n",
            "Result with C = 6.5\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98       274\n",
            "           1       0.92      0.79      0.85        42\n",
            "\n",
            "    accuracy                           0.96       316\n",
            "   macro avg       0.94      0.89      0.91       316\n",
            "weighted avg       0.96      0.96      0.96       316\n",
            "\n",
            "Result with C = 7.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98       274\n",
            "           1       0.92      0.79      0.85        42\n",
            "\n",
            "    accuracy                           0.96       316\n",
            "   macro avg       0.94      0.89      0.91       316\n",
            "weighted avg       0.96      0.96      0.96       316\n",
            "\n",
            "Result with C = 7.5\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98       274\n",
            "           1       0.92      0.79      0.85        42\n",
            "\n",
            "    accuracy                           0.96       316\n",
            "   macro avg       0.94      0.89      0.91       316\n",
            "weighted avg       0.96      0.96      0.96       316\n",
            "\n",
            "Result with C = 8.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98       274\n",
            "           1       0.92      0.79      0.85        42\n",
            "\n",
            "    accuracy                           0.96       316\n",
            "   macro avg       0.94      0.89      0.91       316\n",
            "weighted avg       0.96      0.96      0.96       316\n",
            "\n",
            "Result with C = 8.5\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98       274\n",
            "           1       0.92      0.79      0.85        42\n",
            "\n",
            "    accuracy                           0.96       316\n",
            "   macro avg       0.94      0.89      0.91       316\n",
            "weighted avg       0.96      0.96      0.96       316\n",
            "\n",
            "Result with C = 9.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98       274\n",
            "           1       0.92      0.79      0.85        42\n",
            "\n",
            "    accuracy                           0.96       316\n",
            "   macro avg       0.94      0.89      0.91       316\n",
            "weighted avg       0.96      0.96      0.96       316\n",
            "\n",
            "Result with C = 9.5\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98       274\n",
            "           1       0.92      0.79      0.85        42\n",
            "\n",
            "    accuracy                           0.96       316\n",
            "   macro avg       0.94      0.89      0.91       316\n",
            "weighted avg       0.96      0.96      0.96       316\n",
            "\n",
            "Result with C = 10.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98       274\n",
            "           1       0.92      0.79      0.85        42\n",
            "\n",
            "    accuracy                           0.96       316\n",
            "   macro avg       0.94      0.89      0.91       316\n",
            "weighted avg       0.96      0.96      0.96       316\n",
            "\n",
            "The best accuracy was with 0.9651898734177216 with C= 10.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0PreyWdRo-43",
        "colab_type": "text"
      },
      "source": [
        "### Bài tập 3.\n",
        " - <ins>Yêu cầu</ins>: Ý tưởng của hàm ``kernel`` $K(\\dots, \\dots)$ là gì? Khi nào chúng ta áp dụng hàm ``kernel``? Chúng ta có cần biết biểu thức của hàm $\\Phi(x)$ không?\n",
        " 1. Kernel SVM là việc đi tìm một hàm số biến đổi dữ liệu $x$ từ không gian feature ban đầu thành dữ liệu trong một không gian mới bằng hàm số $\\Phi(\\mathbf{x})$. Hàm số này cần thoả mãn mục đích đó là tronng không gian mới, dữ liệu giữa hai classes là phân biệt tuyến tính hoặc gần như phần biệt tuyến tính.\n",
        " 2. Chúng ta áp dụng hàm ``kernel`` khi dữ liệu không phân biệt tuyến tính, Với dữ liệu gần phân biệt tuyến tính, linear và poly kernels cho kết quả tốt hơn.\n",
        " 3. Ta cần phải biết biểu thức của hàm $\\Phi(x)$ vì với mỗi bộ dữ liệu sẽ có những hàm kernels khác nhau từ đó chúng ta sẽ phải chọn những hàm $\\Phi(x)$ tương ứng.\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bi7R74Uvo-44",
        "colab_type": "text"
      },
      "source": [
        "### Bài tập 4.\n",
        " - <ins>Yêu cầu</ins>: Cho điểm dữ liệu trong không gian hai chiều $x = [x_1, x_2]^T$ và hàm biến đổi sang không gian năm chiều $\\Phi(x) = [1, \\sqrt{2}x_1, \\sqrt{2}x_2, x_1^2, \\sqrt{2}x_1x_2, x_2^2]^T$. Hãy tính hàm ``kernel`` $K(a, b)$.\n",
        "\n",
        "\\begin{eqnarray}\n",
        "\\Phi(\\mathbf{x})^T\\Phi(\\mathbf{z}) &=& [1, \\sqrt{2} x_1, \\sqrt{2} x_2, x_1^2, \\sqrt{2} x_1x_2, x_2^2] [1, \\sqrt{2} z_1, \\sqrt{2} z_2, z_1^2, \\sqrt{2} z_1z_2, z_2^2]^T \\\\\n",
        "&=& 1 + 2x_1z_1 + 2x_2z_2 + x_1^2x_2^2 + 2x_1z_1x_2z_2 + x_2^2z_2^2 \\\\\n",
        "&=& (1 + x_1z_1 + x_2z_2)^2 = (1 + \\mathbf{x}^T\\mathbf{z})^2 = k(\\mathbf{x}, \\mathbf{z})\n",
        "\\end{eqnarray}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7e0F4e_o-44",
        "colab_type": "text"
      },
      "source": [
        "### Bài tập 5.\n",
        " - <ins>Yêu cầu</ins>: Giả sử bạn dùng bộ phân loại ``SVM`` với hàm ``kernel`` (radial basis function) ``RBF`` cho tập huấn luyện và thấy mô hình phân loại chưa tốt. Để cải thiện, bạn sẽ giảm hay tăng tham số $\\gamma$ trong công thức hàm ``kernel``, tham số ``C`` trong hàm mất mát."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyfbDY0xo-45",
        "colab_type": "text"
      },
      "source": [
        "### Bài tập 6. (Exercise 9 trang 174, Chapter 5: Support Vector Machines)\n",
        " - <ins>Yêu cầu</ins>: Huấn luyện một bộ phân lớp ``SVM`` dựa trên bộ dữ liệu ``MNIST`` (dùng để phân loại hình ảnh các ký tự số có cùng kích thước). Bởi vì bộ phân loại ``SVM`` là bộ phân lớp nhị phân, chúng ta sẽ cần sử dụng chiến thuật ``one-versus-the-rest`` để phân loại tất cả ``10`` ký tự số (trong thực tế chúng ta chỉ dùng chiến thuật ``one-versus-one`` trong các trường hợp dữ liệu nhỏ). Bạn hãy báo cáo độ chính xác (``accuracy``) của mô hình đã huấn luyện trên tập test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5DdCG1So-46",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.svm import LinearSVC\n",
        "mnist = fetch_openml('mnist_784', version=1, cache=True)\n",
        "\n",
        "X = mnist[\"data\"]\n",
        "y = mnist[\"target\"].astype(np.uint8)\n",
        "\n",
        "X_train = X[:60000]\n",
        "y_train = y[:60000]\n",
        "X_test = X[60000:]\n",
        "y_test = y[60000:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTOMA2ZIpMBn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "af07be81-e1f0-45a0-ee19-3a43c9481fab"
      },
      "source": [
        "# %%\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "lin_clf = LinearSVC(random_state=42)\n",
        "lin_clf.fit(X_train, y_train)\n",
        "y_pred = lin_clf.predict(X_train)\n",
        "accuracy_score(y_train, y_pred)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8733"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4me3Hf-pM6g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b12261e2-2c76-444a-aa34-a55d15b4b966"
      },
      "source": [
        "# %%\n",
        "y_test_predict =lin_clf.predict(X_test)\n",
        "accuracy_score(y_test, y_test_predict)\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8579"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gzKTaRLpYZZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %%\n",
        "Scaler = StandardScaler()\n",
        "X_train_scaled = Scaler.fit_transform(X_train.astype(np.float32))\n",
        "X_test_scaled = Scaler.fit_transform(X_test.astype(np.float32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFydqxtdpZXj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "4ce5df91-ef77-4a0d-c3cd-c9098e1d14a4"
      },
      "source": [
        "# %%\n",
        "lin_clf = LinearSVC(random_state =42)\n",
        "lin_clf.fit(X_train, y_train)\n",
        "y_pred = lin_clf.predict(X_train)\n",
        "accuracy_score(y_train, y_pred)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8733"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lL1UKtMLplQu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %%\n",
        "y_test_predict = lin_clf.predict(X_test_scaled)\n",
        "accuracy_score(y_test, y_test_predict)\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import reciprocal, uniform\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import reciprocal, uniform\n",
        "from sklearn.svm import SVC"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaJ-HtuEpqfP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3f1077ec-4f0d-43bd-9506-2982a41077f9"
      },
      "source": [
        "# %%\n",
        "svm_clf = SVC(gamma=\"scale\")\n",
        "svm_clf.fit(X_train_scaled[:10000], y_train[:10000])\n",
        "\n",
        "param_distributions = {\"gamma\": reciprocal(0.001, 0.1), \"C\": uniform(1, 10)}\n",
        "rnd_search_cv = RandomizedSearchCV(svm_clf, param_distributions, n_iter=10, verbose=2, cv=3)\n",
        "rnd_search_cv.fit(X_train_scaled[:1000], y_train[:1000])\n",
        "\n",
        "rnd_search_cv.best_estimator_\n",
        "rnd_search_cv.best_score_"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
            "[CV] C=5.325819085503509, gamma=0.03453401040247756 ..................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ... C=5.325819085503509, gamma=0.03453401040247756, total=   1.3s\n",
            "[CV] C=5.325819085503509, gamma=0.03453401040247756 ..................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.3s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ... C=5.325819085503509, gamma=0.03453401040247756, total=   1.3s\n",
            "[CV] C=5.325819085503509, gamma=0.03453401040247756 ..................\n",
            "[CV] ... C=5.325819085503509, gamma=0.03453401040247756, total=   1.3s\n",
            "[CV] C=4.8923736429585345, gamma=0.03028902207214891 .................\n",
            "[CV] .. C=4.8923736429585345, gamma=0.03028902207214891, total=   1.3s\n",
            "[CV] C=4.8923736429585345, gamma=0.03028902207214891 .................\n",
            "[CV] .. C=4.8923736429585345, gamma=0.03028902207214891, total=   1.3s\n",
            "[CV] C=4.8923736429585345, gamma=0.03028902207214891 .................\n",
            "[CV] .. C=4.8923736429585345, gamma=0.03028902207214891, total=   1.3s\n",
            "[CV] C=9.603778741035674, gamma=0.0026579407084473105 ................\n",
            "[CV] . C=9.603778741035674, gamma=0.0026579407084473105, total=   1.1s\n",
            "[CV] C=9.603778741035674, gamma=0.0026579407084473105 ................\n",
            "[CV] . C=9.603778741035674, gamma=0.0026579407084473105, total=   1.1s\n",
            "[CV] C=9.603778741035674, gamma=0.0026579407084473105 ................\n",
            "[CV] . C=9.603778741035674, gamma=0.0026579407084473105, total=   1.1s\n",
            "[CV] C=1.455714621276968, gamma=0.022411646186496863 .................\n",
            "[CV] .. C=1.455714621276968, gamma=0.022411646186496863, total=   1.3s\n",
            "[CV] C=1.455714621276968, gamma=0.022411646186496863 .................\n",
            "[CV] .. C=1.455714621276968, gamma=0.022411646186496863, total=   1.3s\n",
            "[CV] C=1.455714621276968, gamma=0.022411646186496863 .................\n",
            "[CV] .. C=1.455714621276968, gamma=0.022411646186496863, total=   1.3s\n",
            "[CV] C=3.3639531171034145, gamma=0.0031662556540383497 ...............\n",
            "[CV]  C=3.3639531171034145, gamma=0.0031662556540383497, total=   1.2s\n",
            "[CV] C=3.3639531171034145, gamma=0.0031662556540383497 ...............\n",
            "[CV]  C=3.3639531171034145, gamma=0.0031662556540383497, total=   1.2s\n",
            "[CV] C=3.3639531171034145, gamma=0.0031662556540383497 ...............\n",
            "[CV]  C=3.3639531171034145, gamma=0.0031662556540383497, total=   1.2s\n",
            "[CV] C=3.8169009613148543, gamma=0.00295604373723256 .................\n",
            "[CV] .. C=3.8169009613148543, gamma=0.00295604373723256, total=   1.1s\n",
            "[CV] C=3.8169009613148543, gamma=0.00295604373723256 .................\n",
            "[CV] .. C=3.8169009613148543, gamma=0.00295604373723256, total=   1.1s\n",
            "[CV] C=3.8169009613148543, gamma=0.00295604373723256 .................\n",
            "[CV] .. C=3.8169009613148543, gamma=0.00295604373723256, total=   1.2s\n",
            "[CV] C=1.3545555652503674, gamma=0.005199267158681707 ................\n",
            "[CV] . C=1.3545555652503674, gamma=0.005199267158681707, total=   1.2s\n",
            "[CV] C=1.3545555652503674, gamma=0.005199267158681707 ................\n",
            "[CV] . C=1.3545555652503674, gamma=0.005199267158681707, total=   1.2s\n",
            "[CV] C=1.3545555652503674, gamma=0.005199267158681707 ................\n",
            "[CV] . C=1.3545555652503674, gamma=0.005199267158681707, total=   1.2s\n",
            "[CV] C=8.06655394621435, gamma=0.06785138726197235 ...................\n",
            "[CV] .... C=8.06655394621435, gamma=0.06785138726197235, total=   1.3s\n",
            "[CV] C=8.06655394621435, gamma=0.06785138726197235 ...................\n",
            "[CV] .... C=8.06655394621435, gamma=0.06785138726197235, total=   1.3s\n",
            "[CV] C=8.06655394621435, gamma=0.06785138726197235 ...................\n",
            "[CV] .... C=8.06655394621435, gamma=0.06785138726197235, total=   1.3s\n",
            "[CV] C=4.918174926331993, gamma=0.06416448524916278 ..................\n",
            "[CV] ... C=4.918174926331993, gamma=0.06416448524916278, total=   1.3s\n",
            "[CV] C=4.918174926331993, gamma=0.06416448524916278 ..................\n",
            "[CV] ... C=4.918174926331993, gamma=0.06416448524916278, total=   1.3s\n",
            "[CV] C=4.918174926331993, gamma=0.06416448524916278 ..................\n",
            "[CV] ... C=4.918174926331993, gamma=0.06416448524916278, total=   1.3s\n",
            "[CV] C=7.91922924779478, gamma=0.011782549700913268 ..................\n",
            "[CV] ... C=7.91922924779478, gamma=0.011782549700913268, total=   1.3s\n",
            "[CV] C=7.91922924779478, gamma=0.011782549700913268 ..................\n",
            "[CV] ... C=7.91922924779478, gamma=0.011782549700913268, total=   1.3s\n",
            "[CV] C=7.91922924779478, gamma=0.011782549700913268 ..................\n",
            "[CV] ... C=7.91922924779478, gamma=0.011782549700913268, total=   1.3s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:   37.5s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8319816822810835"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0kpefEVprRD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %%\n",
        "rnd_search_cv.best_estimator_.fit(X_train_scaled,y_train)\n",
        "# %%\n",
        "y_pred = rnd_search_cv.best_estimator_.predict(X_train_scaled)\n",
        "accuracy_score(y_train, y_pred)\n",
        "# %% \n",
        "y_pred = rnd_search_cv.best_estimator_.predict(X_test_scaled)\n",
        "accuracy_score(y_test, y_pred)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "As1ZuFneo-49",
        "colab_type": "text"
      },
      "source": [
        "### Bài tập 7. (Exercise 10 trang 174, Chapter 5: Support Vector Machines)\n",
        " - <ins>Yêu cầu</ins>: Hãy huấn luyện một mô hình hồi quy tuyến tính với dữ liệu giá nhà ``California housing dataset``."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35pKerZEo-4-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "housing = fetch_california_housing()\n",
        "X = housing[\"data\"]\n",
        "y = housing[\"target\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLsDjZJ3x5ag",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %%\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "Scaler = StandardScaler()\n",
        "X_train_scaled = Scaler.fit_transform(X_train)\n",
        "X_test_scaled = Scaler.fit_transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7C5LtEeox6Fp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "outputId": "2c445a81-6736-487a-e65c-d29caea6dd62"
      },
      "source": [
        "# %%\n",
        "from sklearn.svm import LinearSVR\n",
        "from sklearn.svm import LinearSVC\n",
        "lin_svr = LinearSVC(random_state = 42)\n",
        "lin_svr.fit(X_train_scaled, y_train)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-64e7f1568ea1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msvm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLinearSVC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlin_svr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mlin_svr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/svm/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    234\u001b[0m                          \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"C\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m                          accept_large_sparse=False)\n\u001b[0;32m--> 236\u001b[0;31m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36mcheck_classification_targets\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    167\u001b[0m     if y_type not in ['binary', 'multiclass', 'multiclass-multioutput',\n\u001b[1;32m    168\u001b[0m                       'multilabel-indicator', 'multilabel-sequences']:\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unknown label type: %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Unknown label type: 'continuous'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjDzUcIHx7xi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "outputId": "1dee808e-36e9-4204-90cf-8a3d9ac9d549"
      },
      "source": [
        "# %%\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "y_pred = lin_svr.predict(X_train_scaled)\n",
        "mse = mean_squared_error(y_train, y_pred)\n",
        "mse"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotFittedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-782ce7120728>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlin_svr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m         \"\"\"\n\u001b[0;32m--> 293\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    264\u001b[0m             \u001b[0;32mclass\u001b[0m \u001b[0mwould\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         \"\"\"\n\u001b[0;32m--> 266\u001b[0;31m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m    965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 967\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    968\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotFittedError\u001b[0m: This LinearSVC instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qH5kKpKTx-Vq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %%\n",
        "import numpy as np \n",
        "np.sqrt(mse)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Z1yjz8zx_-h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %%\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import reciprocal , uniform\n",
        "param_distributions = {\"gamma\": reciprocal(0.001, 0.1), \"C\": uniform(1, 10)}\n",
        "rnd_search_cv = RandomizedSearchCV(SVR(), param_distributions, n_iter=10, verbose=2, cv=3, random_state=42)\n",
        "rnd_search_cv.fit(X_train_scaled, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjs8aXL3yDKw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %%\n",
        "rnd_search_cv.best_estimator_ \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzUFzxFhyExh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %%\n",
        "y_pred = rnd_search_cv.best_estimator_.predict(X_train_scaled)\n",
        "mse = mean_squared_error(y_train, y_pred)\n",
        "np.sqrt(mse)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGjyjjibyIXh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %%\n",
        "y_pred = rnd_search_cv.best_estimator_.predict(X_test_scaled)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "np.sqrt(mse)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}